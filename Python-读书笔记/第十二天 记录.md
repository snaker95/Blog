---
title: 第十二天 记录 lxml.html第三方模块
categories: 读书笔记
tags: 读书笔记-Python
keywords: [Python]
description: Python lxml.html第三方模块

---

<!--more-->

[TOC]

# 第十二天 记录
## 1. lxml.html模块学习步骤
学习内容主要包括以下几个方面:

* 解析HTML
   * 解析HTML段落
   * 中断了的页面
* 获取HTML元素方法
* 使用E-factory创建HTML
   * 实例
   * 查看生成的网页
* 使用链接
   * 相关方法
* form表单
   * form表单填充
   * form 表单提交
* 清理HTML

## 2. 解析HTML
### 解析HTML段落的相关方法: `lxml.html`
* `.parse(filename_url_or_file)`
    可以解析来至URL或者文件读取来的字符串, 若为URL: 通过*传递*或者*geturl()*方法获取到的URL; 若为文件: 通过*传递的文件/URL*或者*read()*方法的对象

* `.document_fromstring(string)`
    把字符串解析成为完整HTML文档对象

* `.fragment_fromstring(string, create_parent=False)`
    解析字符串为HTML对象, 并完成, 当sreate_parent部位False, 则创建父级

* `.fragments_fromstring(string)`
    返回一个在HTML段落中发现的元素对象list

* `.fromstring(string)`
    返回根据传递的string一个完整或者不完整的HTML

```python
import lxml.html
# 1.
url = 'http://www.sharedsea.com/'
parse_html = lxml.html.parse(url)
print parse_html.docinfo
print parse_html.parser
# 2.
html_str = '<a>a LINK </a>'
document = lxml.html.document_fromstring(html_str)
print lxml.html.tostring(document)
# <html><body><a>a LINK </a></body></html>
# 3. 
document = lxml.html.fragment_fromstring(html_str,create_parent='div')
print lxml.html.tostring(document)
# <div><a>a LINK </a></div>
# 4.
html_str = '<a>a LINK </a><b>a BOLB </b>'
print lxml.html.fragments_fromstring(html_str)
# [<Element a at 0x107909d08>, <Element b at 0x107909d60>]

```

### 3. 获取HTML元素的方法
HTML元素具有所有`ElementTree`的方法, 除此之外, 还包括一些扩展方法:

* `.drop_tree()`
删除该元素和它的所有子元素

* `.drop_tag()`
删除该标签, 但是保留子元素和内容

* `.find_class('class_name')`
获取所有class为'class_name'的元素列表

* `.find_rel_links(rel)`
获取所有\<a rel={rel}\> 元素的列表,E.g., doc.find_rel_links('tag')则获取所有被标记为`tag`的链接

* `.get_element_by_id(id, default=None)`
获取id的元素,否则为None

* `.text_content()`
获取该元素下的内容, 包括子元素标签.

* `.cssselect(expr)`
通过css选择器进行获取元素, 和xpath(expr)有相同效果

* `.label`
获取该元素相关的<label>标签, 若不存在则返回None

* `.base_url`
获取这个元素的基本Url, 若为设置则为None

* `.classes`
返回一个集合对象，允许访问和修改元素的类属性和名称

* `.set(key, value=None)`
设置该元素的属性和属性值

### 4. 使用E-factory创建HTML
1. 实例
2. 查看生成的网页 `open_in_browser()`

```python
from lxml.html import builder as E
# import lxml.html.usedoctest
html = E.HTML(
    E.HEAD(
        E.LINK(rel="stylesheet", href="great.css", type="text/css")
        ,E.TITLE('Test')
    )
    ,E.BODY(
        E.H1(E.CLASS("heading"), "Top News"),
        E.P("World News only on this page", style="font-size: 200%"),
        "Ah, and here's some more text, by the way.",
        lxml.html.fromstring("<p>... and this is a parsed fragment ...</p>")
    )
)
print lxml.html.tostring(html)
lxml.html.open_in_browser(html)
```

### 5. 使用links
1. 相关元素的方法
    * `.iterlinks()`
    获取所有的link链接, 包括action, archive, background, cite, classid, codebase, data, href, longdesc, profile, src, usemap, dynsrc, or lowsrc attribute等,但是不包括\<base href\>. 不存在则返回None
    
    * `.resolve_base_href()`
    修改\<base href>\, 同时移除原有标签
    
    * `.make_links_absolute(base_href, resolve_base_href=True)`
    修改为绝对url, 若resolve_base_href为True, 则所有的\<base href>\都会执行.
    
    * `.rewrite_links(link_repl_func, resolve_base_href=True, base_href=None)`
    通过link_repl_func方法重写文档中所有的链接

2. 普通函数
    * `iterlinks(html)`
    * `resolve_base_href(html)`
    * `make_links_absolute(html, base_href, resolve_base_href=True)`
    * `rewrite_links(html, link_repl_func, resolve_base_href=True, base_href=None)`
    **PS:** 这些功能将解析HTML如果它是一个字符串，然后返回新的 HTML字符串。如果通过一个文件，该文件将被复制 （除iterlinks()），执行的方法，并返回新的文件。

### 6. form表单
&nbsp;&nbsp;&nbsp;&nbsp;通过doc.form[0] 获取第一个form表单

* 1. 基本方法
    * input/select/textarea
        * `.name`
        * `.value` 
    
    * select
        * `.value_options` 获取所有select下option的值
        * `.multiple` 若为`<select multiple>`则为True
    
    * input
        * `.type` 获取input的type属性值
        * `.checkable` 若该input可以被选择(type=checkbox/radio),则返回True
        * `.checked` 元素被选中装态, 否则会报`AttributeError`异常
        
    * others
        * `.inputs` 获取form表单中的input对应元素, 以字典类型返回
        * `.fields` 获取form表单中input对应的name和value值, 以字典类型返回
        * `.form_values()` 返回有name,value组成的元祖的列表, [(name, value),...]
        * `.action` 获取form表单提交的URL
        * `.method` 获取form表单提交方式, 'GET or POST'

* 2. 填充表单

```python
from lxml.html import fromstring, tostring
form_page = fromstring('''<html><body><form>
  Your name: <input type="text" name="name"> <br>
  Your phone: <input type="text" name="phone"> <br>
  Your favorite pets: <br>
  Dogs: <input type="checkbox" name="interest" value="dogs"> <br>
  Cats: <input type="checkbox" name="interest" value="cats"> <br>
  Llamas: <input type="checkbox" name="interest" value="llamas"> <br>
  <input type="submit"></form></body></html>''')
form = form_page.forms[0]
form.fields = dict(
  name='John Smith',
  phone='555-555-3949',
  interest=set(['cats', 'llamas']))
print tostring(form)
"""<html>
 <body>
   <form>
   Your name:
     <input name="name" type="text" value="John Smith">
     <br>Your phone:
     <input name="phone" type="text" value="555-555-3949">
     <br>Your favorite pets:
     <br>Dogs:
     <input name="interest" type="checkbox" value="dogs">
     <br>Cats:
     <input checked name="interest" type="checkbox" value="cats">
     <br>Llamas:
     <input checked name="interest" type="checkbox" value="llamas">
     <br>
     <input type="submit">
   </form>
 </body>
</html>"""
```

* 3. 提交表单
通过lxml.html.submit_form(form_element)提交表单, 返回file对象(the result of urllib.urlopen()).
通过使用`extra_values`来添加扩展input值, extra_values = {'name':'value'}.
可以通过`open_http()`验证提交状态, open_http(method, url, values).

```python
>>> from lxml.html import parse, submit_form
>>> page = parse('http://tinyurl.com').getroot()
>>> page.forms[1].fields['url'] = 'http://lxml.de/'
>>> result = parse(submit_form(page.forms[1])).getroot()
>>> [a.attrib['href'] for a in result.xpath("//a[@target='_blank']")]
['http://tinyurl.com/2xae8s', 'http://preview.tinyurl.com/2xae8s']
```

### 7. 清理HTML
通过lxml.html.clean模块中的Cleaner类来清理HTML页面, 支持清理嵌入或者脚本类型的内容/特殊标签/CSS/注释等.

```python
html = '''
    <html>
     <head>
       <script type="text/javascript" src="evil-site"></script>
       <link rel="alternate" type="text/rss" src="evil-rss">
       <style>
         body {background-image: url(javascript:do_evil)};
         div {color: expression(evil)};
       </style>
     </head>
     <body onload="evil_function()">
       <!-- I am interpreted for EVIL! -->
       <a href="javascript:evil_function()">a link</a>
       <a href="#" onclick="evil_function()">another link</a>
       <p onclick="evil_function()">a paragraph</p>
       <div style="display: none">secret EVIL!</div>
       <object> of EVIL! </object>
       <iframe src="evil-site"></iframe>
       <form action="evil-site">
         Password: <input type="password" name="password">
       </form>
       <blink>annoying EVIL!</blink>
       <a href="evil-site">spam spam SPAM!</a>
       <image src="evil!">
     </body>
    </html>
'''
```

* 清理所有怀疑的元素和内容, `clean_html()`

```python
>>> from lxml.html.clean import clean_html
>>> print clean_html(html)
"""
<div><style>/* deleted */</style><body>

   <a href="">a link</a>
   <a href="#">another link</a>
   <p>a paragraph</p>
   <div>secret EVIL!</div>
    of EVIL!


     Password:
   annoying EVIL!<a href="evil-site">spam spam SPAM!</a>
   <img src="evil!"></body></div>
"""
```

* 使用Cleaner类自定义清理内容

```python
"""
    Instances cleans the document of each of the possible offending
    elements.  The cleaning is controlled by attributes; you can
    override attributes in a subclass, or set them in the constructor.

    ``scripts``:
        Removes any ``<script>`` tags. 
        Default True

    ``javascript``:
        Removes any Javascript, like an ``onclick`` attribute. 
        Also removes stylesheets as they could contain Javascript.
        Default True

    ``comments``:
        Removes any comments.
        Default True

    ``style``:
        Removes any style tags.
        Default False

    ``inline_style``
        Removes any style attributes.  
        Defaults to the value of the ``style`` option.
        Default None

    ``links``:
        Removes any ``<link>`` tags
        Default True

    ``meta``:
        Removes any ``<meta>`` tags
        Default True

    ``page_structure``:
        Structural parts of a page: ``<head>``, ``<html>``, ``<title>``.
        Default True

    ``processing_instructions``:
        Removes any processing instructions.
        Default True

    ``embedded``:
        Removes any embedded objects (flash, iframes)
        Default True

    ``frames``:
        Removes any frame-related tags
        Default True

    ``forms``:
        Removes any form tags
        Default True

    ``annoying_tags``:
        Tags that aren't *wrong*, but are annoying.  
        ``<blink>`` and ``<marquee>``.
        Default True

    ``remove_tags``:
        A list of tags to remove.  Only the tags will be removed,
        their content will get pulled up into the parent tag.
        Default None

    ``kill_tags``:
        A list of tags to kill.  Killing also removes the tag's content,
        i.e. the whole subtree, not just the tag itself.
        Default None

    ``allow_tags``:
        A list of tags to include (default include all).
        Default None

    ``remove_unknown_tags``:
        Remove any tags that aren't standard parts of HTML.
        Default True

    ``safe_attrs_only``:
        If true, only include 'safe' attributes (specifically the list
        from the feedparser HTML sanitisation web site).
        Default True

    ``safe_attrs``:
        A set of attribute names to override the default list of attributes considered 'safe' (when safe_attrs_only=True).

    ``add_nofollow``:
        If true, then any <a> tags will have ``rel="nofollow"`` added to them.
        Default True

    ``host_whitelist``:
        A list or set of hosts that you can use for embedded content
        (for content like ``<object>``, ``<link rel="stylesheet">``, etc).
        You can also implement/override the method
        ``allow_embedded_url(el, url)`` or ``allow_element(el)`` to
        implement more complex rules for what can be embedded.
        Anything that passes this test will be shown, regardless of
        the value of (for instance) ``embedded``.

        Note that this parameter might not work as intended if you do not
        make the links absolute before doing the cleaning.

        Note that you may also need to set ``whitelist_tags``.
        
        Default ()

    ``whitelist_tags``:
        A set of tags that can be included with ``host_whitelist``.
        The default is ``iframe`` and ``embed``; you may wish to
        include other tags like ``script``, or you may want to
        implement ``allow_embedded_url`` for more control.  Set to None to
        include all tags.
        Default set(['iframe', 'embed'])

    This modifies the document *in place*.
"""

>>> from lxml.html.clean import Cleaner

>>> cleaner = Cleaner(page_structure=False, links=False)
>>> print cleaner.clean_html(html)
"""
<html>
  <head>
    <link rel="alternate" src="evil-rss" type="text/rss">
    <style>/* deleted */</style>
  </head>
  <body>
    <a href="">a link</a>
    <a href="#">another link</a>
    <p>a paragraph</p>
    <div>secret EVIL!</div>
    of EVIL!
    Password:
    annoying EVIL!
    <a href="evil-site">spam spam SPAM!</a>
    <img src="evil!">
  </body>
</html>
"""
>>> cleaner = Cleaner(style=True, links=True, add_nofollow=True,
...                   page_structure=False, safe_attrs_only=False)

>>> print cleaner.clean_html(html)
"""
<html>
  <head>
  </head>
  <body>
    <a href="">a link</a>
    <a href="#">another link</a>
    <p>a paragraph</p>
    <div>secret EVIL!</div>
    of EVIL!
    Password:
    annoying EVIL!
    <a href="evil-site" rel="nofollow">spam spam SPAM!</a>
    <img src="evil!">
  </body>
</html>
"""
```

### 8. 获取某URL下提交表单字段

```python
import lxml.html
import pprint
import urllib2
def parse_form(url):
    data = {}

    try:
        html = urllib2.urlopen(url).read()
    except Exception as e:
        html = None
    if html is None: return data

    tree = lxml.html.fromstring(html)

    for e in tree.cssselect('form input'):
        if e.get('name'):
            data[e.get('name')] = e.get('value')

    return data

pprint.pprint(parse_form(url))(url):

```

**参考文章:**
[http://lxml.de/lxmlhtml.html](http://lxml.de/lxmlhtml.html)
Author [@Snaker95][1]

[1]: http://www.sharedsea.com